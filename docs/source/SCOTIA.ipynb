{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **SCOTIA Analysis of CCI**"
      ],
      "metadata": {
        "id": "oFaYzzDV9tDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   The SCOTIA documentation and package could be found  here:\n",
        "https://github.com/Caochris/SCOTIA\n",
        "*   The paper could be found here:\n",
        "https://www.nature.com/articles/s41588-024-01890-9\n"
      ],
      "metadata": {
        "id": "Z1GQ7TPmDB6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. **Import Package**"
      ],
      "metadata": {
        "id": "djilFQCrDhco"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7ASkB9C9orD"
      },
      "outputs": [],
      "source": [
        "import scotia\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scanpy as sc\n",
        "import anndata as ad\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from scipy.spatial import distance_matrix\n",
        "from scipy.stats import ranksums\n",
        "from matplotlib.collections import LineCollection\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E1lFkcvZDm_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. **Run the Analysis**\n",
        "\n",
        "\n",
        "\n",
        "*   The below shows an example analysis on analyzing spot level data, where I have prepared the data by the following columns: `[\"x\", \"y\", \"celltypeA\",..., \"celltypeX\", \"cell_type(dominant cell type)\", \"GeneA\",..., \"GeneX\"]`.\n",
        "*   According to their paper, they use the LR pairs from the [FANTOM5 database](https://doi.org/10.1038/ncomms8866)\n",
        "*   According to their paper, they do the permutation for 50 times, but we increase to 500 times.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-YrEiyBEDnWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for num in [\"slice1\"]:\n",
        "  path_exprsn = f'/rsrch5/home/biostatistics/lku/ILIBD/data/{num}/exprsn_df.csv'\n",
        "\n",
        "  data = pd.read_csv(path_exprsn, index_col=0)\n",
        "  data = data.dropna(subset=['cell_type'])\n",
        "  gene_expression= data.drop(columns=[\"x\",\"y\",\"cell\",\"Excitatory_neurons\",\"Inhibitory_neuron\", \"Astrocyte\", \"Oligodendrocyte\",\"Oligodendrocyte_precursor_cell\",\n",
        "                    \"Microglia\",\"Pericytes\", \"Endothelial_cells\",\"cell_type\" ])\n",
        "  meta_data = data[[\"cell\",\"x\",\"y\",\"cell_type\"]]\n",
        "  meta_data.loc[:,'cell_id'] = meta_data['cell']\n",
        "  meta_data.set_index('cell', inplace=True)\n",
        "  meta_data['fov'] = 0\n",
        "  meta_data.loc[:,'x_positions'] = meta_data['x']\n",
        "  meta_data.loc[:,'y_positions'] = meta_data['y']\n",
        "  meta_data.loc[:, 'x_pos'] = meta_data['x']\n",
        "  meta_data.loc[:, 'y_pos'] = meta_data['y']\n",
        "  meta_data.loc[:, 'sample'] = \"test\"\n",
        "  meta_data.loc[:,'annotation'] = meta_data['cell_type']\n",
        "  meta_df = meta_data[[\"cell_id\", \"fov\"   , \"annotation\" , \"x_positions\" , \"y_positions\",'sample','x_pos','y_pos']]\n",
        "  cell_types = []\n",
        "  cell_indices = []\n",
        "  meta_df_fov = meta_df\n",
        "  meta_df_fov['index'] = range(meta_df_fov.shape[0])\n",
        "  cell_type_l = list(set(meta_df_fov['annotation']))\n",
        "\n",
        "\n",
        "  # Generate the Null Distribution\n",
        "\n",
        "  for ct in cell_type_l:\n",
        "    meta_df_sel = meta_df_fov[meta_df_fov['annotation']==ct]\n",
        "    idx_l = np.array(meta_df_sel['index'])\n",
        "    cell_types.append(ct)\n",
        "    cell_indices.append(list(idx_l))\n",
        "  # Create the resulting DataFrame\n",
        "  cluster_cell_df = pd.DataFrame({'cell_type': cell_types, 'cell_idx': cell_indices})\n",
        "  coord = np.array(meta_df[['x_positions','y_positions']])\n",
        "  S_all_arr = distance_matrix(coord,coord)\n",
        "  dis_mtx_mod = scotia.sel_pot_inter_cluster_pairs(S_all_arr,cluster_cell_df)\n",
        "  exp_df = gene_expression\n",
        "  exp_df['cell_id'] = exp_df.index\n",
        "  exp_df['fov'] = 0\n",
        "  first_columns = ['cell_id', 'fov']\n",
        "\n",
        "  # Reorder the columns: first_columns + all other columns not in first_columns\n",
        "  exp_df = exp_df[first_columns + [col for col in exp_df.columns if col not in first_columns]]\n",
        "  exp_df = exp_df.reset_index(drop=True)\n",
        "  meta_df1 = meta_df[['cell_id','fov','annotation','x_positions','y_positions']]\n",
        "  meta_df1 = meta_df1.reset_index(drop=True)\n",
        "  #known LR pairs\n",
        "  known_lr_pairs = pd.read_csv('/rsrch5/home/biostatistics/lku/FANTOM5_db.csv', index_col=0)\n",
        "  known_lr_pairs = known_lr_pairs.reset_index(drop=True)\n",
        "  valid_genes = set(exp_df.columns)\n",
        "  known_lr_pairs1 = known_lr_pairs[known_lr_pairs['l_gene'].isin(valid_genes)]\n",
        "  known_lr_pairs = known_lr_pairs1[known_lr_pairs1['r_gene'].isin(valid_genes)]\n",
        "  ## infer the null ot\n",
        "  inter_likely_df = scotia.source_target_ot(dis_mtx_mod, exp_df, meta_df1, known_lr_pairs)\n",
        "  inter_likely_df.columns = ['source_cell_idx','receptor_cell_idx','likelihood','ligand_recptor','source_cell_type','target_cell_type']\n",
        "  inter_likely_df['cell_pairs'] = inter_likely_df['source_cell_type']+\"-\"+ inter_likely_df['target_cell_type']\n",
        "  ## infer the null avg likelihood\n",
        "  group = \"test\"\n",
        "  inter_likely_df['cell_pairs'] = inter_likely_df['source_cell_type']+\"_\"+ inter_likely_df['target_cell_type']\n",
        "  null_final_summary = scotia.post_ot(inter_likely_df,label=group)\n",
        "  null_final_summary.to_csv(f'/rsrch5/home/biostatistics/lku/ILIBD/data/{num}/null_ot_SCOTIA_result.csv', index=False)\n",
        "\n",
        "  #permutation test\n",
        "  #gene expression normalization factor\n",
        "  gene_expression= data.drop(columns=[\"x\", \"y\", \"cell_type\", \"cell\"])\n",
        "  exp_df_all = gene_expression\n",
        "  exp_df_norm = exp_df_all.iloc[:,0:]\n",
        "  exp_df_norm = exp_df_norm[exp_df_norm>0]\n",
        "  df_quantile = exp_df_norm.quantile(q=0.99,axis = 0)\n",
        "  fov = 0\n",
        "  cluster_df = cluster_cell_df\n",
        "  cluster_df.columns = ['cell_type','cell_idx']\n",
        "\n",
        "  #coordinates\n",
        "  meta_df_fov = meta_df1[meta_df1['fov']==fov]\n",
        "  meta_df_fov.index = range(meta_df_fov.shape[0])\n",
        "  cell_id_all = np.array(range(meta_df_fov.shape[0]))\n",
        "  coord = np.array(meta_df_fov[['x_positions','y_positions']])\n",
        "  S_all_arr = distance_matrix(coord,coord)\n",
        "\n",
        "  #expression\n",
        "  exp_df_fov = exp_df[exp_df['fov']==fov].iloc[:,2:]\n",
        "  exp_df_fov = exp_df_fov/df_quantile\n",
        "  exp_df_fov[exp_df_fov>1] = 1\n",
        "  exp_df_fov.index = cell_id_all\n",
        "\n",
        "  # Generate the Permutation Coordinates and Cell Types\n",
        "  it_n = 500\n",
        "  #get permutated positions and expression\n",
        "  random_pos, shuffled_exp = scotia.permutation_test(coord,int(it_n))\n",
        "  #select potentially communicating cell cluster pairs (spatially adjacent)\n",
        "  S_all_arr_new = scotia.sel_pot_inter_cluster_pairs(S_all_arr,cluster_df)\n",
        "\n",
        "  final_summary = pd.DataFrame([])\n",
        "  for i_n in range(int(it_n)):\n",
        "    exp_df_permu = exp_df_fov.loc[list(shuffled_exp.iloc[:,i_n])]\n",
        "    coord_permu = np.array(random_pos.iloc[:,i_n*2:i_n*2+2])\n",
        "    S_all_arr_permu = distance_matrix(coord_permu,coord_permu)\n",
        "    mask = np.where(S_all_arr_new==np.inf)\n",
        "    S_all_arr_permu[mask] = np.inf\n",
        "    # optimal transport\n",
        "    ga_df_permu = scotia.source_target_ot(S_all_arr_permu, exp_df_permu, meta_df_fov, known_lr_pairs)\n",
        "    if ga_df_permu.shape[0]>0:\n",
        "      ga_df_permu.columns = ['source_cell_idx','receptor_cell_idx','likelihood','ligand_recptor','source_cell_type','target_cell_type']\n",
        "\n",
        "      #post-processing ot results by calculating averaged likelihoods\n",
        "      ga_df_permu['cell_pairs'] = ga_df_permu['source_cell_type']+\"_\"+ga_df_permu['target_cell_type']\n",
        "      final_summary_tmp = scotia.post_ot(ga_df_permu, label=group, it_n_label = i_n)\n",
        "      final_summary = pd.concat([final_summary,final_summary_tmp])\n",
        "      final_summary.to_csv(f'/rsrch5/home/biostatistics/lku/ILIBD/data/{num}/permu_ot_SCOTIA_result.csv', index=False)\n",
        "\n",
        "  ###########summary for permutation test ####################\n",
        "  fov = 0\n",
        "  it_n = 500\n",
        "  group = 'test'\n",
        "\n",
        "  df_ot = pd.DataFrame([])\n",
        "  df_permu = pd.DataFrame([])\n",
        "\n",
        "  compare_dic ={}\n",
        "  #import ot result\n",
        "  df_ot_tmp = null_final_summary\n",
        "  if df_ot_tmp.shape[0]>0:\n",
        "    df_ot = pd.concat([df_ot,df_ot_tmp])\n",
        "  #import permutation result\n",
        "  df_permu_tmp = final_summary\n",
        "  if df_permu_tmp.shape[0]>0:\n",
        "    df_permu = pd.concat([df_permu,df_permu_tmp])\n",
        "  df_ot['lr_pairs'] = [x.split('|')[0] for x in df_ot['label']]\n",
        "  df_ot['cell_pairs'] = [x.split('|')[2] for x in df_ot['label']]\n",
        "\n",
        "  df_permu['it_n'] = [x.split('|')[-1] for x in df_permu['label']]\n",
        "  df_permu['lr_pairs'] = [x.split('|')[0] for x in df_permu['label']]\n",
        "  df_permu['label_new'] = df_permu['lr_pairs']+\"|\"+df_permu['it_n'].map(str)\n",
        "  df_permu['cell_pairs'] = [x.split('|')[2] for x in df_permu['label']]\n",
        "  # Assuming meta_df1 contains the annotation column with unique cell types\n",
        "  unique_cell_types = meta_df1['annotation'].unique()\n",
        "\n",
        "  # Initialize the larger DataFrame to store all results\n",
        "  result_df = pd.DataFrame()\n",
        "  # Iterate over all combinations of c_t_1 and c_t_2\n",
        "  for c_t_1, c_t_2 in itertools.product(unique_cell_types, repeat=2):\n",
        "    # Initialize variables specific to the combination\n",
        "    c_t_p = c_t_1 + \"_\" + c_t_2\n",
        "    df_ot_tmp = df_ot[df_ot['cell_pairs'] == c_t_p]\n",
        "    df_permu_tmp = df_permu[df_permu['cell_pairs'] == c_t_p]\n",
        "    # Dictionary to store comparisons\n",
        "    compare_dic = {}\n",
        "    if df_permu_tmp.shape[0] > 0:\n",
        "      df_ot_groupby = df_ot_tmp.groupby(['label'])['ave_likelihood'].sum().to_frame().reset_index()\n",
        "      df_ot_groupby.index = [x.split('|')[0] for x in df_ot_groupby['label']]\n",
        "      df_permu_groupby = df_permu_tmp.groupby(['label_new'])['ave_likelihood'].sum()\n",
        "      for i in df_ot_groupby.index:\n",
        "        compare_dic[i + \"|\" + group + \"|\" + c_t_p] = 0\n",
        "        df_permu_groupby_sel = df_permu_groupby[df_permu_groupby.index.str.contains(i + r\"\\|\")]\n",
        "        for j in df_permu_groupby_sel:\n",
        "          if j > df_ot_groupby.loc[i, 'ave_likelihood']:\n",
        "            compare_dic[i + \"|\" + group + \"|\" + c_t_p] += 1 / it_n\n",
        "      p_l = [round(x, 3) for x in compare_dic.values()]\n",
        "      # Adjust p-values using FDR correction\n",
        "      if len(p_l) > 0:\n",
        "        pvalue_adj = multipletests(p_l, alpha=0.05, method='fdr_bh')[1]\n",
        "        pvalue_adj = [round(x, 3) for x in pvalue_adj]\n",
        "        temp_df = pd.DataFrame({\n",
        "            'comparison': compare_dic.keys(),\n",
        "            'p_value': p_l,\n",
        "            'p_value_adj': pvalue_adj,\n",
        "            'c_t_p': c_t_p\n",
        "            })\n",
        "         #Append to the larger result DataFrame\n",
        "        result_df = pd.concat([result_df, temp_df], ignore_index=True)\n",
        "      else:\n",
        "        print(f\"No significant comparisons for {c_t_p}. Skipping.\")\n",
        "  # Final DataFrame with all results\n",
        "  result_df.reset_index(drop=True, inplace=True)\n",
        "  # Split the \"comparison\" column by \"|\" and extract the first element as \"interaction_name\"\n",
        "  result_df['interaction_name'] = result_df['comparison'].str.split('|').str[0]\n",
        "  # Split the \"c_t_p\" column by \"_\" to extract \"ligand\" and \"receptor\"\n",
        "  def split_c_t_p(value):\n",
        "    parts = value.split('_', 1)  # Split only at the first \"_\"\n",
        "    if len(parts) == 2:\n",
        "      return parts[0], parts[1]\n",
        "    else:\n",
        "      return parts[0], None\n",
        "  result_df[['ligand', 'receptor']] = result_df['c_t_p'].apply(split_c_t_p).apply(pd.Series)\n",
        "  result_df['pvalue'] = result_df['p_value_adj']\n",
        "  merged_df = pd.merge(result_df, null_final_summary, left_on='comparison', right_on='label', how='left')\n",
        "  final_summary = merged_df[['ligand','receptor','interaction_name','ave_likelihood','pvalue']]\n",
        "  path_write_LR = f'/rsrch5/home/biostatistics/lku/ILIBD/data/{num}/scotia_result.csv'\n",
        "  final_summary.to_csv(path_write_LR , index=False)"
      ],
      "metadata": {
        "id": "UxIi47e2Ds4Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}